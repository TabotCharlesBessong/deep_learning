{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7adb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # models\n",
    "import pandas as pd # data manipulation\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import datetime # manipulating dates\n",
    "import os # accessing directory structure\n",
    "import random # shuffling data\n",
    "import cv2 # computer vision\n",
    "import seaborn as sns # plotting\n",
    "import sklearn # machine learning\n",
    "from sklearn.model_selection import train_test_split # splitting data\n",
    "from sklearn.metrics import confusion_matrix, roc_curve # model evaluation\n",
    "from PIL import Image # manipulating images\n",
    "import albumentations as A # data augmentation\n",
    "import tensorflow_datasets as tfds # loading datasets\n",
    "import tensorflow_probability as tfp # probabilistic models\n",
    "from tensorflow.keras.models import Model # creating models\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Dense, Flatten, InputLayer, BatchNormalization, Input, Dropout, RandomFlip, RandomRotation, Resizing, Rescaling # creating layers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, FalsePositives, FalseNegatives, TruePositives, TrueNegatives, Precision, Recall, AUC, binary_accuracy # creating evaluation metrics\n",
    "from tensorflow.keras.optimizers import Adam # optimizers\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger,EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau # callbacks\n",
    "from tensorflow.keras.regularizers import L1, L2 # regularization\n",
    "from tensorboard.plugins.hparams import api as hp # hyperparameter tuning\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d420a",
   "metadata": {},
   "source": [
    "### Wandb Install, Login, Initialization and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\group\\anaconda3\\lib\\site-packages (0.24.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (2.37.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\group\\appdata\\roaming\\python\\python312\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "# %pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9293978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a959d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_info = tfds.load('malaria', with_info=True,\n",
    "                                  as_supervised=True, \n",
    "                                  shuffle_files = True, \n",
    "                                  split='train')  # Use string instead of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3586360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704d3f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(151, 115, 3), dtype=uint8, numpy=\n",
      "array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# dataset.head()\n",
    "for data in dataset.take(1):  # dataset is now directly the train split\n",
    "  print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67eea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee82d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n",
    "  DATASET_SIZE = len(dataset)\n",
    "\n",
    "  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
    "\n",
    "  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
    "  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
    "\n",
    "  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n",
    "  return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca78403",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO )\n",
    "#print(list(train_dataset.take(1).as_numpy_iterator()),\n",
    " #     list(val_dataset.take(1).as_numpy_iterator()), list(test_dataset.take(1).as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb62332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977701ab",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
    "  ax = plt.subplot(4, 4, i + 1)\n",
    "  \n",
    "  plt.imshow(image)\n",
    "  plt.title(dataset_info.features['label'].int2str(label))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, label) in enumerate(train_dataset.take(2)):\n",
    "  plt.subplot(1, 4, 2*i + 1)\n",
    "  plt.imshow(image)\n",
    "\n",
    "  plt.subplot(1, 4, 2*i + 2)\n",
    "  plt.imshow(tf.image.adjust_saturation(image, 0.3))\n",
    "\n",
    "\n",
    "  plt.title(dataset_info.features['label'].int2str(label))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85f853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parasitized'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info.features['label'].int2str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928cf88",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbdada",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df3a061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(original, augmented):\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.imshow(original)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.imshow(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29f6579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff660c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image = tf.image.adjust_saturation(original_image, saturation_factor = 0.3)#central_crop(original_image, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80796247",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(original_image, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee7a0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ec8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image, label = next(iter(train_dataset))\n",
    "@tf.function\n",
    "def resize_rescale(image, label):\n",
    "  #print(\"I was here\")\n",
    "  #tf.print(\"I was here\")\n",
    "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label\n",
    "\n",
    "_, _ = resize_rescale(original_image, label)\n",
    "_, _ = resize_rescale(original_image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae943c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b15208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tf.keras.layer resizing and rescaling\n",
    "resize_rescale_layers = tf.keras.Sequential([\n",
    "       Resizing(IM_SIZE, IM_SIZE),\n",
    "       Rescaling(1./255),                               \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d0cd189",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tf.image augment\n",
    "@tf.function\n",
    "def augment(image, label):\n",
    "  image, label = resize_rescale(image, label)\n",
    "\n",
    "  image = tf.image.rot90(image)\n",
    "  #image = tf.image.adjust_saturation(image, saturation_factor = 0.3)\n",
    "  image = tf.image.flip_left_right(image)\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "018f8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotNinety(Layer):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "  @tf.function\n",
    "  def call(self, image):\n",
    "    return tf.image.rot90(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "756d9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RandomContrast\n",
    "from tensorflow.keras.layers import RandomContrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b99d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tf.keras.layer augment\n",
    "augment_layers = tf.keras.Sequential([\n",
    "       RandomRotation(factor = (0.25, 0.2501),),\n",
    "       RandomFlip(mode='horizontal',),\n",
    "       RandomContrast(factor=0.1),\n",
    "                                  \n",
    "])\n",
    "\n",
    "@tf.function\n",
    "def augment_layer(image, label):\n",
    "  return augment_layers(resize_rescale_layers(image), training = True), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2634d69",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a41121",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5951a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "#train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84e00e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], shape=(151, 115, 3), dtype=uint8) tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_dataset.take(1):\n",
    "  print(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b82f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "  train_dataset\n",
    "  .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n",
    "  .map(augment_layer, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  .batch(BATCH_SIZE)\n",
    "  .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b9dfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (\n",
    "    val_dataset\n",
    "    .shuffle(buffer_size = 32)\n",
    "    .map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00cec0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51d4a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a0e05",
   "metadata": {},
   "source": [
    "Mlxup Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bf36c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_1 = train_dataset.shuffle(buffer_size = 4096, ).map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "train_dataset_2 = train_dataset.shuffle(buffer_size = 4096, ).map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\n",
    "mixed_dataset = tf.data.Dataset.zip((train_dataset_1, train_dataset_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78e6da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(train_dataset_1, train_dataset_2):\n",
    "  (image_1,label_1), (image_2, label_2) = train_dataset_1, train_dataset_2\n",
    "\n",
    "  lamda = tfp.distributions.Beta(0.2,0.2)\n",
    "  lamda = lamda.sample(1)[0]\n",
    "  \n",
    "  image = lamda*image_1 + (1-lamda)*image_2\n",
    "  label = lamda*tf.cast(label_1, dtype = tf.float32) + (1-lamda)*tf.cast(label_2, dtype = tf.float32)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45338fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = (\n",
    "    mixed_dataset\n",
    "    .shuffle(buffer_size = 4096, reshuffle_each_iteration = True)\n",
    "    .map(mixup, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    #map(cutmix, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "258b8e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9de24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
