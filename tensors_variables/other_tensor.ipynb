{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e402d9fe",
   "metadata": {},
   "source": [
    "# Advanced Tensor Types and Variables in TensorFlow\n",
    "\n",
    "This notebook explores advanced tensor types and variables in TensorFlow:\n",
    "- **Ragged Tensors**: For handling sequences of different lengths\n",
    "- **Sparse Tensors**: For efficiently storing tensors with many zero values\n",
    "- **String Tensors**: For working with text data\n",
    "- **Variables**: For mutable tensors that can be updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df49b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.1\n",
      "NumPy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8165b9",
   "metadata": {},
   "source": [
    "## 1. Ragged Tensors\n",
    "\n",
    "Ragged tensors are tensors with non-uniform shapes along one or more dimensions. They're perfect for handling sequences of different lengths, like sentences in natural language processing or variable-length time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310f3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragged tensor from sentences:\n",
      "<tf.RaggedTensor [[b'I', b'love', b'machine', b'learning'],\n",
      " [b'TensorFlow', b'is', b'awesome'],\n",
      " [b'Deep', b'learning', b'models', b'are', b'powerful', b'tools']]>\n",
      "Shape: (3, None)\n",
      "Dtype: <dtype: 'string'>\n",
      "\n",
      "Ragged tensor from numbers: <tf.RaggedTensor [[1, 2, 3, 4], [5, 6], [7, 8, 9, 10, 11]]>\n",
      "Shape: (3, None)\n"
     ]
    }
   ],
   "source": [
    "# Creating ragged tensors from nested Python lists\n",
    "# Example: Sentences with different word counts\n",
    "sentences = [\n",
    "    [\"I\", \"love\", \"machine\", \"learning\"],\n",
    "    [\"TensorFlow\", \"is\", \"awesome\"],\n",
    "    [\"Deep\", \"learning\", \"models\", \"are\", \"powerful\", \"tools\"]\n",
    "]\n",
    "\n",
    "ragged_sentences = tf.ragged.constant(sentences)\n",
    "print(\"Ragged tensor from sentences:\")\n",
    "print(ragged_sentences)\n",
    "print(f\"Shape: {ragged_sentences.shape}\")\n",
    "print(f\"Dtype: {ragged_sentences.dtype}\")\n",
    "\n",
    "# Another example with numbers\n",
    "numbers = [[1, 2, 3, 4], [5, 6], [7, 8, 9, 10, 11]]\n",
    "ragged_numbers = tf.ragged.constant(numbers)\n",
    "print(f\"\\nRagged tensor from numbers: {ragged_numbers}\")\n",
    "print(f\"Shape: {ragged_numbers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4980750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragged tensor from row splits:\n",
      "<tf.RaggedTensor [[1, 2, 3, 4], [5, 6], [7, 8, 9]]>\n",
      "\n",
      "Ragged tensor from row lengths: <tf.RaggedTensor [[1, 2, 3, 4], [5, 6], [7, 8, 9]]>\n",
      "\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "# Creating ragged tensors from value and row_splits\n",
    "values = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "row_splits = tf.constant([0, 4, 6, 9])  # Boundaries for each row\n",
    "\n",
    "ragged_from_splits = tf.RaggedTensor.from_row_splits(values, row_splits)\n",
    "print(\"Ragged tensor from row splits:\")\n",
    "print(ragged_from_splits)\n",
    "\n",
    "# Creating using from_row_lengths\n",
    "row_lengths = tf.constant([4, 2, 3])  # Length of each row\n",
    "ragged_from_lengths = tf.RaggedTensor.from_row_lengths(values, row_lengths)\n",
    "print(f\"\\nRagged tensor from row lengths: {ragged_from_lengths}\")\n",
    "\n",
    "# Verify they're the same\n",
    "print(f\"\\nAre they equal? {tf.reduce_all(ragged_from_splits == ragged_from_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13f39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ragged tensor:\n",
      "<tf.RaggedTensor [[1, 2, 3, 4], [5, 6], [7, 8, 9, 10, 11]]>\n",
      "\n",
      "Doubled values: <tf.RaggedTensor [[2, 4, 6, 8], [10, 12], [14, 16, 18, 20, 22]]>\n",
      "\n",
      "Sum of each row: [10 11 45]\n",
      "Total sum: 66\n",
      "Length of each row: [4 2 5]\n",
      "\n",
      "First row: [1 2 3 4]\n",
      "Element at [1, 1]: 6\n",
      "\n",
      "Converted to regular tensor (padded with -1):\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4 -1]\n",
      " [ 5  6 -1 -1 -1]\n",
      " [ 7  8  9 10 11]], shape=(3, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Operations on ragged tensors\n",
    "print(\"Original ragged tensor:\")\n",
    "print(ragged_numbers)\n",
    "\n",
    "# Mathematical operations\n",
    "doubled = ragged_numbers * 2\n",
    "print(f\"\\nDoubled values: {doubled}\")\n",
    "\n",
    "# Reduction operations\n",
    "row_sums = tf.reduce_sum(ragged_numbers, axis=1)\n",
    "print(f\"\\nSum of each row: {row_sums}\")\n",
    "\n",
    "total_sum = tf.reduce_sum(ragged_numbers)\n",
    "print(f\"Total sum: {total_sum}\")\n",
    "\n",
    "# Length operations\n",
    "row_lengths = tf.map_fn(tf.size, ragged_numbers, dtype=tf.int32)\n",
    "print(f\"Length of each row: {row_lengths}\")\n",
    "\n",
    "# Indexing\n",
    "print(f\"\\nFirst row: {ragged_numbers[0]}\")\n",
    "print(f\"Element at [1, 1]: {ragged_numbers[1, 1]}\")\n",
    "\n",
    "# Converting to regular tensor (if possible)\n",
    "try:\n",
    "    regular_tensor = ragged_numbers.to_tensor(default_value=-1)\n",
    "    print(f\"\\nConverted to regular tensor (padded with -1):\")\n",
    "    print(regular_tensor)\n",
    "except Exception as e:\n",
    "    print(f\"Error converting to tensor: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6483b63",
   "metadata": {},
   "source": [
    "## 2. Sparse Tensors\n",
    "\n",
    "Sparse tensors efficiently represent tensors that have many zero values. They store only the non-zero values along with their indices, which can save significant memory for large, sparse datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bcce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse tensor:\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]\n",
      " [3 2]], shape=(4, 2), dtype=int64), values=tf.Tensor([10 20 30 40], shape=(4,), dtype=int32), dense_shape=tf.Tensor([4 4], shape=(2,), dtype=int64))\n",
      "\n",
      "Indices:\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]\n",
      " [3 2]]\n",
      "\n",
      "Values:\n",
      "[10 20 30 40]\n",
      "\n",
      "Dense shape: [4 4]\n",
      "\n",
      "Dense representation:\n",
      "[[ 0 10  0  0]\n",
      " [20  0  0  0]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0 40  0]]\n"
     ]
    }
   ],
   "source": [
    "# Creating sparse tensors\n",
    "# Method 1: Using indices, values, and dense_shape\n",
    "indices = [[0, 1], [1, 0], [2, 3], [3, 2]]  # Locations of non-zero values\n",
    "values = [10, 20, 30, 40]  # Non-zero values\n",
    "dense_shape = [4, 4]  # Shape of the full tensor\n",
    "\n",
    "sparse_tensor = tf.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=dense_shape\n",
    ")\n",
    "\n",
    "print(\"Sparse tensor:\")\n",
    "print(sparse_tensor)\n",
    "print(f\"\\nIndices:\\n{sparse_tensor.indices}\")\n",
    "print(f\"\\nValues:\\n{sparse_tensor.values}\")\n",
    "print(f\"\\nDense shape: {sparse_tensor.dense_shape}\")\n",
    "\n",
    "# Convert to dense tensor to visualize\n",
    "dense_version = tf.sparse.to_dense(sparse_tensor)\n",
    "print(f\"\\nDense representation:\\n{dense_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b3360b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dense matrix:\n",
      "tf.Tensor(\n",
      "[[0. 0. 3. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 7. 0. 0.]\n",
      " [2. 0. 0. 9.]], shape=(4, 4), dtype=float32)\n",
      "\n",
      "Sparse version:\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 3]], shape=(4, 2), dtype=int64), values=tf.Tensor([3. 7. 2. 9.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([4 4], shape=(2,), dtype=int64))\n",
      "\n",
      "Scaled sparse tensor (values * 2):\n",
      "tf.Tensor(\n",
      "[[ 0 20  0  0]\n",
      " [40  0  0  0]\n",
      " [ 0  0  0 60]\n",
      " [ 0  0 80  0]], shape=(4, 4), dtype=int32)\n",
      "\n",
      "Second sparse tensor (identity-like):\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]], shape=(4, 4), dtype=int32)\n",
      "\n",
      "Matrix multiplication result:\n",
      "tf.Tensor(\n",
      "[[  0  20   0   0]\n",
      " [ 20   0   0   0]\n",
      " [  0   0   0 120]\n",
      " [  0   0 120   0]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating sparse tensor from dense tensor\n",
    "dense_matrix = tf.constant([\n",
    "    [0, 0, 3, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 7, 0, 0],\n",
    "    [2, 0, 0, 9]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "print(\"Original dense matrix:\")\n",
    "print(dense_matrix)\n",
    "\n",
    "# Convert dense to sparse\n",
    "sparse_from_dense = tf.sparse.from_dense(dense_matrix)\n",
    "print(f\"\\nSparse version:\")\n",
    "print(sparse_from_dense)\n",
    "\n",
    "# Operations on sparse tensors\n",
    "# Element-wise operations\n",
    "scaled_sparse = tf.sparse.map_values(lambda x: x * 2, sparse_tensor)\n",
    "print(f\"\\nScaled sparse tensor (values * 2):\")\n",
    "print(tf.sparse.to_dense(scaled_sparse))\n",
    "\n",
    "# Sparse matrix multiplication\n",
    "# Create another sparse matrix\n",
    "indices2 = [[0, 0], [1, 1], [2, 2], [3, 3]]\n",
    "values2 = [1, 2, 3, 4]\n",
    "sparse_tensor2 = tf.SparseTensor(indices2, values2, [4, 4])\n",
    "\n",
    "print(f\"\\nSecond sparse tensor (identity-like):\")\n",
    "print(tf.sparse.to_dense(sparse_tensor2))\n",
    "\n",
    "# Matrix multiplication\n",
    "result = tf.sparse.sparse_dense_matmul(sparse_tensor, tf.sparse.to_dense(sparse_tensor2))\n",
    "print(f\"\\nMatrix multiplication result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cca552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced sparse tensor operations:\n",
      "Sum of all elements: 21.0\n",
      "Sum along axis 0: [2. 7. 3. 9.]\n",
      "\n",
      "Reordered sparse tensor (same values, sorted indices):\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]\n",
      " [3 2]], shape=(4, 2), dtype=int64), values=tf.Tensor([10 20 30 40], shape=(4,), dtype=int32), dense_shape=tf.Tensor([4 4], shape=(2,), dtype=int64))\n",
      "\n",
      "Addition of two sparse tensors:\n",
      "tf.Tensor(\n",
      "[[ 1 10  0  0]\n",
      " [20  2  0  0]\n",
      " [ 0  0  3 30]\n",
      " [ 0  0 40  4]], shape=(4, 4), dtype=int32)\n",
      "\n",
      "Sliced sparse tensor [1:3, 1:3]:\n",
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [7. 0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Advanced sparse tensor operations\n",
    "print(\"Advanced sparse tensor operations:\")\n",
    "\n",
    "# Reduction operations\n",
    "sparse_sum = tf.sparse.reduce_sum(sparse_from_dense)\n",
    "print(f\"Sum of all elements: {sparse_sum}\")\n",
    "\n",
    "# Sum along specific axis\n",
    "sparse_sum_axis0 = tf.sparse.reduce_sum(sparse_from_dense, axis=0)\n",
    "print(f\"Sum along axis 0: {sparse_sum_axis0}\")\n",
    "\n",
    "# Reordering sparse tensor\n",
    "reordered = tf.sparse.reorder(sparse_tensor)\n",
    "print(f\"\\nReordered sparse tensor (same values, sorted indices):\")\n",
    "print(reordered)\n",
    "\n",
    "# Adding two sparse tensors\n",
    "sparse_add = tf.sparse.add(sparse_tensor, sparse_tensor2)\n",
    "print(f\"\\nAddition of two sparse tensors:\")\n",
    "print(tf.sparse.to_dense(sparse_add))\n",
    "\n",
    "# Sparse tensor slicing\n",
    "sliced_sparse = tf.sparse.slice(sparse_from_dense, [1, 1], [2, 2])\n",
    "print(f\"\\nSliced sparse tensor [1:3, 1:3]:\")\n",
    "print(tf.sparse.to_dense(sliced_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862395c",
   "metadata": {},
   "source": [
    "## 3. String Tensors\n",
    "\n",
    "TensorFlow provides excellent support for working with string data, including text preprocessing, encoding, and various string operations that are useful for NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c21e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String tensor:\n",
      "tf.Tensor(\n",
      "[b'Hello World' b'TensorFlow' b'Deep Learning'\n",
      " b'Natural Language Processing'], shape=(4,), dtype=string)\n",
      "Shape: (4,)\n",
      "Dtype: <dtype: 'string'>\n",
      "\n",
      "Single string: b'This is a single string tensor'\n",
      "\n",
      "String matrix:\n",
      "[[b'Hello' b'World']\n",
      " [b'Deep' b'Learning']\n",
      " [b'Machine' b'Intelligence']]\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating string tensors\n",
    "text_data = [\"Hello World\", \"TensorFlow\", \"Deep Learning\", \"Natural Language Processing\"]\n",
    "string_tensor = tf.constant(text_data)\n",
    "\n",
    "print(\"String tensor:\")\n",
    "print(string_tensor)\n",
    "print(f\"Shape: {string_tensor.shape}\")\n",
    "print(f\"Dtype: {string_tensor.dtype}\")\n",
    "\n",
    "# Single string tensor\n",
    "single_string = tf.constant(\"This is a single string tensor\")\n",
    "print(f\"\\nSingle string: {single_string}\")\n",
    "\n",
    "# Multidimensional string tensor\n",
    "text_matrix = [\n",
    "    [\"Hello\", \"World\"],\n",
    "    [\"Deep\", \"Learning\"],\n",
    "    [\"Machine\", \"Intelligence\"]\n",
    "]\n",
    "string_matrix = tf.constant(text_matrix)\n",
    "print(f\"\\nString matrix:\\n{string_matrix}\")\n",
    "print(f\"Shape: {string_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d09093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Operations:\n",
      "String lengths: [11 10 13 27]\n",
      "Lowercase: [b'hello world' b'tensorflow' b'deep learning'\n",
      " b'natural language processing']\n",
      "Uppercase: [b'HELLO WORLD' b'TENSORFLOW' b'DEEP LEARNING'\n",
      " b'NATURAL LANGUAGE PROCESSING']\n",
      "Concatenated: b'Prefix_Hello World'\n",
      "\n",
      "Split sentence: [b'This' b'is' b'a' b'sample' b'sentence' b'for' b'splitting']\n",
      "Split CSV: [b'apple' b'banana' b'cherry' b'date']\n",
      "Replaced text: b'Hi world! Hi TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "# String operations\n",
    "print(\"String Operations:\")\n",
    "\n",
    "# String length\n",
    "lengths = tf.strings.length(string_tensor)\n",
    "print(f\"String lengths: {lengths}\")\n",
    "\n",
    "# Convert to lowercase\n",
    "lowercase = tf.strings.lower(string_tensor)\n",
    "print(f\"Lowercase: {lowercase}\")\n",
    "\n",
    "# Convert to uppercase  \n",
    "uppercase = tf.strings.upper(string_tensor)\n",
    "print(f\"Uppercase: {uppercase}\")\n",
    "\n",
    "# String concatenation\n",
    "prefix = tf.constant(\"Prefix_\")\n",
    "concatenated = tf.strings.join([prefix, string_tensor[0]])\n",
    "print(f\"Concatenated: {concatenated}\")\n",
    "\n",
    "# String splitting\n",
    "sentence = tf.constant(\"This is a sample sentence for splitting\")\n",
    "split_words = tf.strings.split(sentence)\n",
    "print(f\"\\nSplit sentence: {split_words}\")\n",
    "\n",
    "# Split with custom delimiter\n",
    "csv_data = tf.constant(\"apple,banana,cherry,date\")\n",
    "split_csv = tf.strings.split(csv_data, sep=\",\")\n",
    "print(f\"Split CSV: {split_csv}\")\n",
    "\n",
    "# String replacement\n",
    "text_with_replacements = tf.constant(\"Hello world! Hello TensorFlow!\")\n",
    "replaced = tf.strings.regex_replace(text_with_replacements, \"Hello\", \"Hi\")\n",
    "print(f\"Replaced text: {replaced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e316328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced String Operations for NLP:\n",
      "Normalized text: [b'hello world!' b'tensorflow is awesome' b'deep learning models']\n",
      "Substring: b'TensorFlow'\n",
      "String to numbers: [123.    456.789 999.   ]\n",
      "Converted dtype: <dtype: 'float32'>\n",
      "\n",
      "Unicode text: b'H\\xc3\\xa9llo W\\xc3\\xb6rld! \\xf0\\x9f\\x8c\\x8d'\n",
      "Unicode length (character count): 14\n",
      "Byte length: 19\n",
      "Unicode codepoints: [    72    233    108    108    111     32     87    246    114    108\n",
      "    100     33     32 127757]\n",
      "Encoded back: b'H\\xc3\\xa9llo W\\xc3\\xb6rld! \\xf0\\x9f\\x8c\\x8d'\n",
      "Unicode characters: [b'H' b'\\xc3\\xa9' b'l' b'l' b'o' b' ' b'W' b'\\xc3\\xb6' b'r' b'l' b'd' b'!'\n",
      " b' ' b'\\xf0\\x9f\\x8c\\x8d']\n",
      "Unicode normalization not available in this TensorFlow version\n"
     ]
    }
   ],
   "source": [
    "# Advanced string operations for NLP\n",
    "print(\"Advanced String Operations for NLP:\")\n",
    "\n",
    "# Text normalization\n",
    "text_samples = tf.constant([\n",
    "    \"  Hello World!  \",\n",
    "    \"TENSORFLOW IS AWESOME\",\n",
    "    \"deep learning models\"\n",
    "])\n",
    "\n",
    "# Strip whitespace and normalize case\n",
    "normalized = tf.strings.strip(text_samples)\n",
    "normalized = tf.strings.lower(normalized)\n",
    "print(f\"Normalized text: {normalized}\")\n",
    "\n",
    "# Substring operations\n",
    "sample_text = tf.constant(\"TensorFlow Deep Learning\")\n",
    "substring = tf.strings.substr(sample_text, 0, 10)  # First 10 characters\n",
    "print(f\"Substring: {substring}\")\n",
    "\n",
    "# String to number conversion\n",
    "numeric_strings = tf.constant([\"123\", \"456.789\", \"999\"])\n",
    "string_to_number = tf.strings.to_number(numeric_strings)\n",
    "print(f\"String to numbers: {string_to_number}\")\n",
    "print(f\"Converted dtype: {string_to_number.dtype}\")\n",
    "\n",
    "# Unicode operations\n",
    "unicode_text = tf.constant(\"H√©llo W√∂rld! üåç\")\n",
    "\n",
    "# Get unicode length by decoding to codepoints first\n",
    "unicode_codepoints = tf.strings.unicode_decode(unicode_text, \"UTF-8\")\n",
    "unicode_length = tf.size(unicode_codepoints)\n",
    "\n",
    "print(f\"\\nUnicode text: {unicode_text}\")\n",
    "print(f\"Unicode length (character count): {unicode_length}\")\n",
    "print(f\"Byte length: {tf.strings.length(unicode_text)}\")\n",
    "\n",
    "print(f\"Unicode codepoints: {unicode_codepoints}\")\n",
    "\n",
    "# Encode back to string\n",
    "encoded_back = tf.strings.unicode_encode(unicode_codepoints, \"UTF-8\")\n",
    "print(f\"Encoded back: {encoded_back}\")\n",
    "\n",
    "# Additional unicode operations\n",
    "# Split unicode text into individual characters\n",
    "unicode_chars = tf.strings.unicode_split(unicode_text, \"UTF-8\")\n",
    "print(f\"Unicode characters: {unicode_chars}\")\n",
    "\n",
    "# Unicode normalization (if available)\n",
    "try:\n",
    "    normalized_unicode = tf.strings.unicode_normalize(unicode_text, \"NFD\")\n",
    "    print(f\"Unicode normalized (NFD): {normalized_unicode}\")\n",
    "except AttributeError:\n",
    "    print(\"Unicode normalization not available in this TensorFlow version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079b02e",
   "metadata": {},
   "source": [
    "## 4. Variables\n",
    "\n",
    "Variables are mutable tensors that maintain their state across function calls. They're essential for machine learning as they store model parameters (weights and biases) that need to be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a0a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Variables:\n",
      "Weight variable: <tf.Variable 'weight:0' shape=() dtype=float32, numpy=5.0>\n",
      "Value: 5.0\n",
      "Dtype: <dtype: 'float32'>\n",
      "Shape: ()\n",
      "\n",
      "Weight matrix variable:\n",
      "<tf.Variable 'weight_matrix:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-0.8210344 , -0.5605073 , -1.6817166 ,  0.20535387],\n",
      "       [ 1.5647713 , -1.8431635 ,  0.04277107,  0.41162834],\n",
      "       [-1.056175  , -0.3251618 ,  1.0506687 , -0.26045057]],\n",
      "      dtype=float32)>\n",
      "\n",
      "Bias variable (initialized with zeros): <tf.Variable 'bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>\n",
      "\n",
      "Variable from tensor: <tf.Variable 'tensor_variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "Is weight a variable? True\n",
      "Is regular tensor a variable? False\n"
     ]
    }
   ],
   "source": [
    "# Creating variables\n",
    "print(\"Creating Variables:\")\n",
    "\n",
    "# Simple variable creation\n",
    "weight = tf.Variable(5.0, name=\"weight\")\n",
    "print(f\"Weight variable: {weight}\")\n",
    "print(f\"Value: {weight.numpy()}\")\n",
    "print(f\"Dtype: {weight.dtype}\")\n",
    "print(f\"Shape: {weight.shape}\")\n",
    "\n",
    "# Matrix variable\n",
    "weight_matrix = tf.Variable(tf.random.normal([3, 4]), name=\"weight_matrix\")\n",
    "print(f\"\\nWeight matrix variable:\")\n",
    "print(weight_matrix)\n",
    "\n",
    "# Variable with specific initialization\n",
    "bias = tf.Variable(tf.zeros([4]), name=\"bias\")\n",
    "print(f\"\\nBias variable (initialized with zeros): {bias}\")\n",
    "\n",
    "# Variable from existing tensor\n",
    "initial_tensor = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "tensor_var = tf.Variable(initial_tensor, name=\"tensor_variable\")\n",
    "print(f\"\\nVariable from tensor: {tensor_var}\")\n",
    "\n",
    "# Check if it's a variable\n",
    "print(f\"\\nIs weight a variable? {isinstance(weight, tf.Variable)}\")\n",
    "print(f\"Is regular tensor a variable? {isinstance(tf.constant(1.0), tf.Variable)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ca3e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Operations:\n",
      "Initial weight value: 5.0\n",
      "After assign(10.0): 10.0\n",
      "After assign_add(5.0): 15.0\n",
      "After assign_sub(3.0): 12.0\n",
      "\n",
      "weight * 2 = 24.0\n",
      "Original weight unchanged: 12.0\n",
      "\n",
      "Original weight matrix:\n",
      "[[-0.8210344  -0.5605073  -1.6817166   0.20535387]\n",
      " [ 1.5647713  -1.8431635   0.04277107  0.41162834]\n",
      " [-1.056175   -0.3251618   1.0506687  -0.26045057]]\n",
      "\n",
      "After updating element [0,0] to 99:\n",
      "[[ 9.9000000e+01 -5.6050730e-01 -1.6817166e+00  2.0535387e-01]\n",
      " [ 1.5647713e+00 -1.8431635e+00  4.2771067e-02  4.1162834e-01]\n",
      " [-1.0561750e+00 -3.2516181e-01  1.0506687e+00 -2.6045057e-01]]\n",
      "\n",
      "After updating row 1:\n",
      "[[99.         -0.5605073  -1.6817166   0.20535387]\n",
      " [ 1.          2.          3.          4.        ]\n",
      " [-1.056175   -0.3251618   1.0506687  -0.26045057]]\n"
     ]
    }
   ],
   "source": [
    "# Variable operations and updates\n",
    "print(\"Variable Operations:\")\n",
    "\n",
    "print(f\"Initial weight value: {weight.numpy()}\")\n",
    "\n",
    "# Update variable using assign\n",
    "weight.assign(10.0)\n",
    "print(f\"After assign(10.0): {weight.numpy()}\")\n",
    "\n",
    "# Update using assign_add\n",
    "weight.assign_add(5.0)\n",
    "print(f\"After assign_add(5.0): {weight.numpy()}\")\n",
    "\n",
    "# Update using assign_sub  \n",
    "weight.assign_sub(3.0)\n",
    "print(f\"After assign_sub(3.0): {weight.numpy()}\")\n",
    "\n",
    "# Mathematical operations (creates new tensors, doesn't modify variable)\n",
    "result = weight * 2\n",
    "print(f\"\\nweight * 2 = {result.numpy()}\")\n",
    "print(f\"Original weight unchanged: {weight.numpy()}\")\n",
    "\n",
    "# Matrix variable operations\n",
    "print(f\"\\nOriginal weight matrix:\")\n",
    "print(weight_matrix.numpy())\n",
    "\n",
    "# Update specific elements\n",
    "weight_matrix[0, 0].assign(99.0)\n",
    "print(f\"\\nAfter updating element [0,0] to 99:\")\n",
    "print(weight_matrix.numpy())\n",
    "\n",
    "# Update entire rows or slices\n",
    "new_row = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "weight_matrix[1, :].assign(new_row)\n",
    "print(f\"\\nAfter updating row 1:\")\n",
    "print(weight_matrix.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05eefe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in Training Simulation:\n",
      "Initial weight: [-0.6460961]\n",
      "Initial bias: [0.]\n",
      "\n",
      "Predictions: [-0.6460961 -1.2921922 -1.9382883 -2.5843844]\n",
      "True values: [2. 4. 6. 8.]\n",
      "Initial loss: 52.51368713378906\n",
      "\n",
      "Gradients - Weight: [-39.691444], Bias: [-13.230481]\n",
      "\n",
      "After one update step:\n",
      "Updated weight: [-0.24918169]\n",
      "Updated bias: [0.1323048]\n",
      "New loss: 36.47075271606445\n",
      "Loss reduction: 16.04293441772461\n"
     ]
    }
   ],
   "source": [
    "# Variables in training simulation\n",
    "print(\"Variables in Training Simulation:\")\n",
    "\n",
    "# Simulate a simple linear model: y = wx + b\n",
    "class SimpleLinearModel:\n",
    "    def __init__(self):\n",
    "        # Initialize weights and bias as variables\n",
    "        self.w = tf.Variable(tf.random.normal([1]), name='weight')\n",
    "        self.b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.w * x + self.b\n",
    "    \n",
    "    def get_variables(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "# Create model\n",
    "model = SimpleLinearModel()\n",
    "print(f\"Initial weight: {model.w.numpy()}\")\n",
    "print(f\"Initial bias: {model.b.numpy()}\")\n",
    "\n",
    "# Generate some sample data\n",
    "x_data = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "y_true = tf.constant([2.0, 4.0, 6.0, 8.0])  # True relationship: y = 2x\n",
    "\n",
    "# Forward pass\n",
    "y_pred = model(x_data)\n",
    "print(f\"\\nPredictions: {y_pred.numpy()}\")\n",
    "print(f\"True values: {y_true.numpy()}\")\n",
    "\n",
    "# Compute loss (mean squared error)\n",
    "loss = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "print(f\"Initial loss: {loss.numpy()}\")\n",
    "\n",
    "# Manual gradient calculation and update (simplified)\n",
    "learning_rate = 0.01\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(x_data)\n",
    "    loss = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "gradients = tape.gradient(loss, model.get_variables())\n",
    "print(f\"\\nGradients - Weight: {gradients[0].numpy()}, Bias: {gradients[1].numpy()}\")\n",
    "\n",
    "# Update variables using gradients\n",
    "model.w.assign_sub(learning_rate * gradients[0])\n",
    "model.b.assign_sub(learning_rate * gradients[1])\n",
    "\n",
    "print(f\"\\nAfter one update step:\")\n",
    "print(f\"Updated weight: {model.w.numpy()}\")\n",
    "print(f\"Updated bias: {model.b.numpy()}\")\n",
    "\n",
    "# Check new loss\n",
    "new_y_pred = model(x_data)\n",
    "new_loss = tf.reduce_mean(tf.square(new_y_pred - y_true))\n",
    "print(f\"New loss: {new_loss.numpy()}\")\n",
    "print(f\"Loss reduction: {loss.numpy() - new_loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced variable features\n",
    "print(\"Advanced Variable Features:\")\n",
    "\n",
    "# Variable constraints\n",
    "constrained_var = tf.Variable(\n",
    "    tf.constant([1.0, -2.0, 3.0]), \n",
    "    constraint=lambda x: tf.clip_by_value(x, 0.0, 10.0),  # Constrain values between 0 and 10\n",
    "    name=\"constrained_variable\"\n",
    ")\n",
    "print(f\"Constrained variable: {constrained_var.numpy()}\")\n",
    "\n",
    "# Try to set values outside the constraint\n",
    "constrained_var.assign([15.0, -5.0, 7.0])  # Values will be clipped\n",
    "print(f\"After assigning [15.0, -5.0, 7.0] (clipped): {constrained_var.numpy()}\")\n",
    "\n",
    "# Trainable vs non-trainable variables\n",
    "trainable_var = tf.Variable(1.0, trainable=True, name=\"trainable\")\n",
    "non_trainable_var = tf.Variable(1.0, trainable=False, name=\"non_trainable\")\n",
    "\n",
    "print(f\"\\nTrainable variable is trainable: {trainable_var.trainable}\")\n",
    "print(f\"Non-trainable variable is trainable: {non_trainable_var.trainable}\")\n",
    "\n",
    "# Variable synchronization (for distributed training)\n",
    "sync_var = tf.Variable(\n",
    "    initial_value=1.0,\n",
    "    synchronization=tf.VariableSynchronization.ON_READ,\n",
    "    aggregation=tf.VariableAggregation.MEAN,\n",
    "    name=\"synchronized_variable\"\n",
    ")\n",
    "print(f\"\\nSynchronized variable: {sync_var}\")\n",
    "\n",
    "# Variable collections and tracking - improved approach\n",
    "print(f\"\\nAll variables created so far:\")\n",
    "try:\n",
    "    # Try to get global variables (might not work in TF 2.x)\n",
    "    global_vars = tf.compat.v1.global_variables()\n",
    "    if global_vars:\n",
    "        for var in global_vars:\n",
    "            if hasattr(var, 'name'):\n",
    "                print(f\"  {var.name}: {var.shape}\")\n",
    "    else:\n",
    "        print(\"  Global variables list is empty or not available in TF 2.x\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not access global variables: {e}\")\n",
    "\n",
    "# Variable checkpointing simulation - improved approach\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    weight=weight,\n",
    "    bias=bias,\n",
    "    weight_matrix=weight_matrix\n",
    ")\n",
    "\n",
    "# Better way to show checkpoint variables\n",
    "checkpoint_vars = {}\n",
    "try:\n",
    "    # Try different ways to access checkpoint information\n",
    "    if hasattr(checkpoint, '_checkpoint_dependencies'):\n",
    "        deps = checkpoint._checkpoint_dependencies\n",
    "        if hasattr(deps, 'keys'):\n",
    "            checkpoint_vars = list(deps.keys())\n",
    "        else:\n",
    "            checkpoint_vars = [\"weight\", \"bias\", \"weight_matrix\"]  # Known variables\n",
    "    else:\n",
    "        checkpoint_vars = [\"weight\", \"bias\", \"weight_matrix\"]  # Known variables\n",
    "except Exception:\n",
    "    checkpoint_vars = [\"weight\", \"bias\", \"weight_matrix\"]  # Fallback\n",
    "\n",
    "print(f\"\\nCheckpoint created with variables: {checkpoint_vars}\")\n",
    "\n",
    "# Save variable state (in practice, you'd save to disk)\n",
    "variable_state = {\n",
    "    'weight': weight.numpy(),\n",
    "    'bias': bias.numpy(), \n",
    "    'weight_matrix': weight_matrix.numpy()\n",
    "}\n",
    "print(f\"Variable state saved: {list(variable_state.keys())}\")\n",
    "\n",
    "# Additional variable inspection\n",
    "print(f\"\\nVariable details:\")\n",
    "print(f\"  weight: shape={weight.shape}, dtype={weight.dtype}, trainable={weight.trainable}\")\n",
    "print(f\"  bias: shape={bias.shape}, dtype={bias.dtype}, trainable={bias.trainable}\")\n",
    "print(f\"  weight_matrix: shape={weight_matrix.shape}, dtype={weight_matrix.dtype}, trainable={weight_matrix.trainable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ab2b5",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Ragged Tensors\n",
    "- **Use case**: Variable-length sequences (sentences, time series)\n",
    "- **Key features**: Non-uniform shapes, memory efficient for irregular data\n",
    "- **Common operations**: Indexing, reduction, conversion to/from regular tensors\n",
    "\n",
    "### Sparse Tensors\n",
    "- **Use case**: Data with many zero values (sparse matrices, embeddings)\n",
    "- **Key features**: Store only non-zero values and their indices\n",
    "- **Common operations**: Matrix multiplication, element-wise operations, reduction\n",
    "\n",
    "### String Tensors\n",
    "- **Use case**: Text processing, NLP tasks\n",
    "- **Key features**: Unicode support, extensive string manipulation functions\n",
    "- **Common operations**: Splitting, joining, case conversion, regex operations\n",
    "\n",
    "### Variables\n",
    "- **Use case**: Model parameters that need to be updated during training\n",
    "- **Key features**: Mutable, persistent state, gradient tracking\n",
    "- **Common operations**: assign, assign_add, assign_sub, constraint enforcement\n",
    "\n",
    "These tensor types form the foundation for advanced TensorFlow applications, especially in deep learning and machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
