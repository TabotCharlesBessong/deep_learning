{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJFWBkN8v45k"
      },
      "source": [
        "# Computer Vision with PyTorch\n",
        "\n",
        "In this notebook we will use a subset dataset from the popular Food101 Dataset.\n",
        "\n",
        "We're going to use 4 different classes:\n",
        "\n",
        "1. Sushi\n",
        "2. Cup-Cakes\n",
        "3. Macarons\n",
        "4. Chocolate Cake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0497U1eywSo4"
      },
      "source": [
        "## 2. Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JP69l8S3wbe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.8.0+cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: PyTorch 1.10.0+ is required for this video\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_71zud2wz3l"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIUon2adxPyl"
      },
      "source": [
        "### Setup Device Agnostic Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv1XRKwbw_Ez"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaX90hcLxNRm"
      },
      "outputs": [],
      "source": [
        "import requests # this library is used to make requests over the internet (HTTP Connection)\n",
        "import zipfile # import zipfile will help you unzip .zip files\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Setup data path\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"food_images\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and parepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory already exists, skipping download.\")\n",
        "else:\n",
        "    print(f\"{image_path} does not exist, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the data zip file\n",
        "with open(data_path / \"food_images.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://programmingoceanacademy.s3.ap-southeast-1.amazonaws.com/image_classification_dataset.zip\")\n",
        "    print(\"Downloading food images data....\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip data file .zip\n",
        "with zipfile.ZipFile(data_path / \"food_images.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping food images .zip file...\")\n",
        "    zip_ref.extractall(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r5dzo1J1Vn8"
      },
      "outputs": [],
      "source": [
        "os.remove(\"./data/food_images.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_jwPYVK1sqM"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Now we have gotten a dataset in our environement successfully in the `Standard Image Classification Format`\n",
        "\n",
        "`data -> food_images -> dataset -> train -> class_a, class_b, class_c`\n",
        "\n",
        "`data -> food_images -> dataset -> test -> class_a, class_b, class_c`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqFI-6Vm2w8M"
      },
      "outputs": [],
      "source": [
        "image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eF5Xa8B2fzc"
      },
      "outputs": [],
      "source": [
        "# Setup directory paths\n",
        "train_dir = image_path / \"dataset/train\"\n",
        "test_dir = image_path / \"dataset/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPbjU8iK23xN"
      },
      "outputs": [],
      "source": [
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgqLn8Hw24XK"
      },
      "outputs": [],
      "source": [
        "test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkEF3is26ob"
      },
      "source": [
        "## 2. Becoming one with the data (data preperation and data exploartion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuz9sFYG3kSW"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in list(os.walk(data_path)):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} in '{dirpath}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLSVXy2r3Euk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "    \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yGBnSZh4LPv"
      },
      "outputs": [],
      "source": [
        "walk_through_dir(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_I9FLFI4Me2"
      },
      "outputs": [],
      "source": [
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs3mDNfI4oLm"
      },
      "outputs": [],
      "source": [
        "test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDcuPFJg5Exk"
      },
      "outputs": [],
      "source": [
        "image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaCBQQcX4pH-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*/*.jpg\"))\n",
        "\n",
        "# 2. Pick a random image image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUxADWW26M22"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # for visuslization in python\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shapes: {img_as_array.shape} -> [height, width, color_channels] (HWC)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpNQFkVF6yqe"
      },
      "outputs": [],
      "source": [
        "img_as_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfH_Nku17nUL"
      },
      "source": [
        "## 3. Transforming Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAuuW3wx7yO-"
      },
      "source": [
        "Before we can use our image data with PyTorch:\n",
        "1. Turn our target data into tensors (in our case, numerical representation of our images)\n",
        "2. Turn it into `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader` we'll call these two `Dataset` and `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torchvision\n",
        "print(torch.__version__)\n",
        "# print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHTfdZ_28FPo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T23nJf5x8X2P"
      },
      "source": [
        "### 3.1 Transforming data with `torchvision.transforms`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKiz0qit9f2t"
      },
      "outputs": [],
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal axis\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation(degrees=180),\n",
        "    # Turn the image into a torch.tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ytsuiGH-oRA"
      },
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xm9yfN-MpG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(data_transform(img).permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LszvC-AW-uvf"
      },
      "outputs": [],
      "source": [
        "data_transform(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KijLEbz7-yW1"
      },
      "outputs": [],
      "source": [
        "image_path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFpe1mCK_TXa"
      },
      "outputs": [],
      "source": [
        "random.sample(image_path_list, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvXzNeUb_7Fg"
      },
      "outputs": [],
      "source": [
        "Image.open(random.choice(image_path_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI5VW0yD-3es"
      },
      "outputs": [],
      "source": [
        "def plot_transformed_images(image_paths: list, transform, n=3, seed=None):\n",
        "\n",
        "    \"\"\"\n",
        "    Selects random images from a path of images and loads/transforms them\n",
        "    then plots the original vs the transformed version.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
        "            ax[0].axis(False)\n",
        "\n",
        "            # Transform and plot target image\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k5t9lXLAe6l"
      },
      "outputs": [],
      "source": [
        "plot_transformed_images(image_paths=image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=3,\n",
        "                        seed=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNo_HeXNBWwA"
      },
      "source": [
        "## 4. Loading Image Data using Image Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDObJcwuBq5n"
      },
      "outputs": [],
      "source": [
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBeXGGq2CEYD"
      },
      "outputs": [],
      "source": [
        "test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpSaj8p4CZCf"
      },
      "outputs": [],
      "source": [
        "data_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpxiXplnCGBr"
      },
      "outputs": [],
      "source": [
        "# Use ImageFolder to create datasets\n",
        "\n",
        "from torchvision import datasets\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_dir, # Fetch images form inside folders\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None) # we don't want to transform the targets of our images\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform,\n",
        "                                 target_transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTIPIE0ICoNQ"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOi06OJACqSE"
      },
      "outputs": [],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyEnRIL7C1L7"
      },
      "outputs": [],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4pvwexHDTw0"
      },
      "outputs": [],
      "source": [
        "# Get class names as list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZL1pPAWDZcm"
      },
      "outputs": [],
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puk646yFDpcF"
      },
      "outputs": [],
      "source": [
        "# Check the lengts of our dataset\n",
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac99iUlnD0-u"
      },
      "outputs": [],
      "source": [
        "train_data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obPxq5PpEBjI"
      },
      "outputs": [],
      "source": [
        "test_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnupIxA_EDRw"
      },
      "outputs": [],
      "source": [
        "image, label = train_data[0][0], train_data[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhWYdzWXEd1u"
      },
      "outputs": [],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmK8stkDEebM"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCKnKhqwEfqo"
      },
      "outputs": [],
      "source": [
        "print(f\"Image tensor:\\n {image}\")\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "print(f\"Image datatype: {image.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0D7E-XyEu09"
      },
      "outputs": [],
      "source": [
        "class_names[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsw_eU4VFA1j"
      },
      "outputs": [],
      "source": [
        "# Rearrange the order of dimensions\n",
        "img_permute = image.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes\n",
        "print(f\"Original shape: {image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permute: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v8nYeXBFmqa"
      },
      "source": [
        "## 4.1 turn loaded images into `DataLoaders`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFT8i_JbGnX4"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9o0virEGkWt"
      },
      "outputs": [],
      "source": [
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXMZc6KCF9wu"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 1 # Batch size is 32 (YOU CAN CHANGE THIS TO WHATEVER YOU WANT)\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False,\n",
        "                             num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3sERTVrG1iS"
      },
      "outputs": [],
      "source": [
        "train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3GAYpnG2mg"
      },
      "outputs": [],
      "source": [
        "test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsZ7bAauG5fD"
      },
      "outputs": [],
      "source": [
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"Image shape: {img_batch.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label batch shape: {label_batch.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9RNSwqoHHb5"
      },
      "outputs": [],
      "source": [
        "label_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVznQzWlHObh"
      },
      "outputs": [],
      "source": [
        "test_image_batch, test_label_batch = next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axUYhatrHYFA"
      },
      "outputs": [],
      "source": [
        "test_label_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JVke3ZgHYyF"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_batch[0].permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbrNPnWSICto"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dl_DwmvHwr2"
      },
      "outputs": [],
      "source": [
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "\n",
        "    # 1. Adjust display if n is too high\n",
        "    if n > 5:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        classes = False\n",
        "        print(f\"For display puporses, n shouldn't be larger than 10, setting to 10 and removing shape display\")\n",
        "\n",
        "    # 2. Set the seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 3. Get rnadom sample indexes\n",
        "    random_sample_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 4. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 5. Loop through random indexes and plot them with matplotlib\n",
        "    for i, targ_sample in enumerate(random_sample_idx):\n",
        "        targ_sample, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 6. Adjust tensor dimensions for plotting\n",
        "        targ_image_adjust = targ_sample.permute(1, 2, 0) # [color_channels, height, width] -> [height, width, color_channels]\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        if classes:\n",
        "            title = f\"Class: {classes[targ_label]}\"\n",
        "            if display_shape:\n",
        "                title = title + f\"\\nShape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQpI2xyIJiWi"
      },
      "outputs": [],
      "source": [
        "# Call the function and plot random images\n",
        "display_random_images(dataset=train_data,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pu0Fm-ZRww1"
      },
      "source": [
        "## 5. Building a computer vision model - image classification model (TinyVGG Architecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhvNa7_FUX7W"
      },
      "outputs": [],
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying the TinyVGG from CNN Explainer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shape: int) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3), # (1x1) (5x5) (7x7) (10x10)\n",
        "                      stride=(1, 1), # 2\n",
        "                      padding=0), # (0 - valid) (1 - padding) (2 - output shape > input_shape)\n",
        "            nn.ReLU(), # learn complex non-linear relationships,\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=(1, 1),\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            # Max Pool helps us reduce overfitting\n",
        "            # Max pool helps us make the processing and computing faster\n",
        "            nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                         stride=(2, 2)) # default stride value is same as kernel_sie\n",
        "        )\n",
        "\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # flatten the feature map matrix into a feature vector (1D) to be able to pass into the linear layer and classify\n",
        "            nn.Linear(in_features=hidden_units*13*13,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv_block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t_EhtZdcBWJ"
      },
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE27ImIKbqUy"
      },
      "outputs": [],
      "source": [
        "data_transform(img).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg8x_U60cU8b"
      },
      "outputs": [],
      "source": [
        "len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7QRe0Y_cb_b"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI3z8Surbdyn"
      },
      "outputs": [],
      "source": [
        "# Instatiating a new instance of the TinyVGG model\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = TinyVGG(input_shape=3, # number of color channels in our image data\n",
        "                hidden_units=10,\n",
        "                output_shape=len(class_names)).to(device)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufgrsCMce38"
      },
      "source": [
        "## 5.1 Try a dummy forward pass by passing a single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-uPghfKehDi"
      },
      "outputs": [],
      "source": [
        "# Get a single image batch and label batch\n",
        "image_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "image_batch.shape, label_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj0na5Nuepni"
      },
      "outputs": [],
      "source": [
        "image_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vd-y1HWe9Cr"
      },
      "outputs": [],
      "source": [
        "label_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XSmDOukfQSe"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGpRpMqHfY5d"
      },
      "outputs": [],
      "source": [
        "image_batch.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpPOUxCRfone"
      },
      "outputs": [],
      "source": [
        "image_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCYU55Hwe9s2"
      },
      "outputs": [],
      "source": [
        "# Try a forward pass\n",
        "logits = model(image_batch.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQZGj_Wtg_Zc"
      },
      "outputs": [],
      "source": [
        "logits.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x372qyPTiG2e"
      },
      "source": [
        "### 5.2 Use `torchinfo` to get an idea of the shapes going through the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSkpU4T4iNNa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install -q torchinfo\n",
        "    import torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6jJL2kicni"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjZVJx5CjNCu"
      },
      "outputs": [],
      "source": [
        "model(image_batch[0].unsqueeze(dim=0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQNqvBWbimwd"
      },
      "outputs": [],
      "source": [
        "summary(model=model,\n",
        "        input_size=[1, 3, 64, 64]) # an example of the input image shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BGnLZBei4Wr"
      },
      "source": [
        "### 6. Creating a training loop and testing loop to train and evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3_CK_UZk50w"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device=device):\n",
        "\n",
        "    \"\"\"\n",
        "    This function will train a model on the dataloader\n",
        "    and optimizes the model's paramters to better represent our data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy value\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # Send data to the target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X) # outputs raw scores (logits)\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() # Accumulate the train loss\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Apply backpropgation algorithm\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step (Gradient Descent Algorithm)\n",
        "        optimizer.step() # to improve the weights and biases of the model\n",
        "\n",
        "        # Calculate accuracy metric\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bz83DBUnfKN"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device=device):\n",
        "\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup the test loss and test accuracy values\n",
        "    test_loss , test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference mode\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "            # Send data to the target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calcualte the loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # 3. Calculate the accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))\n",
        "\n",
        "        # Adjust metrics to get average loss and accuracy per batch\n",
        "        test_loss = test_loss / len(dataloader)\n",
        "        test_acc = test_acc / len(dataloader)\n",
        "\n",
        "\n",
        "        return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIaUej1D3Unz"
      },
      "source": [
        "### Creating a function `train()` to combine `train_step()` and `test_step()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBdce5s-3e34"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "# Combine train_step() and test_step() both and calls them toghether in one hit\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5, # 5 epochs be default\n",
        "          device=device):\n",
        "\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []}\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | test_acc: {test_acc:.4f}\")\n",
        "\n",
        "        # Update the results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_XPvEiM64Wy"
      },
      "outputs": [],
      "source": [
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9QCXW-653Yv"
      },
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model = TinyVGG(input_shape=3,\n",
        "                hidden_units=32,\n",
        "                output_shape=len(class_names)).to(device)\n",
        "\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss() # we are dealing with multi class classification\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model_results = train(model=model,\n",
        "                      train_dataloader=train_dataloader,\n",
        "                      test_dataloader=test_dataloader,\n",
        "                      optimizer=optimizer,\n",
        "                      loss_fn=loss_fn,\n",
        "                      epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time - start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZGmleB0BDnI"
      },
      "outputs": [],
      "source": [
        "# Epoch: 9 | Train Loss: 0.9759 | Train acc: 0.5957 | Test loss: 1.3401 | test_acc: 0.4344\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2YgC2M3-kh0"
      },
      "outputs": [],
      "source": [
        "model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcfSqPXQ-Vp2"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "\n",
        "    \"\"\"Plots training curves of a results dicitionary.\"\"\"\n",
        "\n",
        "\n",
        "    # Get the loss values of the results dictioary (traininig and test)\n",
        "    loss = results[\"train_loss\"]\n",
        "    test_loss = results[\"test_loss\"]\n",
        "\n",
        "    # Get the accuracy values of the results dictioanay (training and test)\n",
        "    accuracy = results[\"train_acc\"]\n",
        "    test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot the loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot the accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label=\"train_acc\")\n",
        "    plt.plot(epochs, test_accuracy, label=\"test_acc\")\n",
        "    plt.title(\"Accuracy %\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9lmww76_0Kk"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BPZuZT8AtcW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
